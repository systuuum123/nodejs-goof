name: "snyk code test"
on: push
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4  # Updated to use Node.js 20

      - name: Set up JQ
        run: sudo apt-get install jq -y

      - uses: snyk/actions/setup@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

      - name: Snyk Test
        run: snyk code test --org=${{ secrets.SNYK_ORG }} --sarif > snyk.sarif
        continue-on-error: true

      - name: Run vulnerability analysis script
        run: |
          #!/bin/bash

          set -e  # Exit immediately if a command exits with a non-zero status

          # Define the SARIF file
          sarif_file="snyk.sarif"

          # Generate the timestamp for the filename
          timestamp=$(date +"%Y%m%d_%H%M%S")
          output_json="vulnerability_report_${timestamp}.json"

          # Check if ../data folder exists, if not create it
          if [ ! -d "../data" ]; then
            mkdir -p ../data
          fi

          # Find the latest file in the ../data directory
          latest_file=$(ls -t ../data/vulnerability_report_*.json 2>/dev/null | head -n 1)

          # Print the name of the latest file that will be used for age calculation
          echo "Latest file to be used for age calculation: $latest_file"

          # Retrieve the descriptions and levels dynamically and store them in arrays
          descriptions=()
          levels=()
          while IFS= read -r line; do
            descriptions+=("$line")
          done < <(jq -r '.runs[].tool.driver.rules[].shortDescription.text' "$sarif_file")

          while IFS= read -r line; do
            levels+=("$line")
          done < <(jq -r '.runs[].tool.driver.rules[].defaultConfiguration.level' "$sarif_file")

          # Define the severity mapping
          declare -A severity_mapping
          severity_mapping=( ["error"]="High" ["warning"]="Medium" ["note"]="Low" )

          # Function to calculate age of a vulnerability based on previous files in ../data
          calculate_age_and_timestamp() {
            local description="$1"
            local uri="$2"
            local start_line="$3"
            local earliest_timestamp=""
            local age=0

            if [[ -z "$latest_file" ]]; then
              echo "0" "new"
              return
            fi

            vulnerabilities=$(jq -c '.[]' "$latest_file")
            while IFS= read -r vulnerability; do
              vuln_desc=$(echo "$vulnerability" | jq -r '.shortDescription')
              vuln_uri=$(echo "$vulnerability" | jq -r '.artifactLocationUri')
              vuln_line=$(echo "$vulnerability" | jq -r '.startLine')
              vuln_timestamp=$(echo "$vulnerability" | jq -r '.timestamp')
              if [[ "$description" == "$vuln_desc" && "$uri" == "$vuln_uri" && "$start_line" == "$vuln_line" ]]; then
                if [[ -z "$earliest_timestamp" || "$vuln_timestamp" < "$earliest_timestamp" ]]; then
                  earliest_timestamp="$vuln_timestamp"
                fi
              fi
            done <<< "$vulnerabilities"

            if [[ -n "$earliest_timestamp" ]]; then
              start_date=$(date -d "${earliest_timestamp:0:8}" +%s)
              current_date=$(date +%s)
              age=$(( (current_date - start_date) / 86400 ))
              echo "$age" "$earliest_timestamp"
            else
              echo "0" "new"
            fi
          }

          # Initialize a temporary file to hold JSON objects
          temp_json="temp.json"
          echo "[]" > "$temp_json"

          # Extract the required fields and store in the JSON array
          for index in "${!descriptions[@]}"; do
            severity="${severity_mapping[${levels[$index]}]}"
            
            vulnerabilities=$(jq --arg index "$index" --arg desc "${descriptions[$index]}" --arg severity "$severity" --arg timestamp "$timestamp" -r \
              '.runs[].results[] | select(.ruleIndex == ($index|tonumber)) | {index: $index|tonumber, shortDescription: $desc, artifactLocationUri: .locations[].physicalLocation.artifactLocation.uri, startLine: .locations[].physicalLocation.region.startLine, severity: $severity, timestamp: $timestamp}' \
              "$sarif_file")

            echo "$vulnerabilities" | jq -c '.' | while IFS= read -r vulnerability; do
              description=$(echo "$vulnerability" | jq -r '.shortDescription')
              uri=$(echo "$vulnerability" | jq -r '.artifactLocationUri')
              start_line=$(echo "$vulnerability" | jq -r '.startLine')
              read -r age original_timestamp <<< $(calculate_age_and_timestamp "$description" "$uri" "$start_line")
              
              if [[ "$original_timestamp" != "new" ]]; then
                timestamp="$original_timestamp"
              fi
              
              updated_vulnerability=$(echo "$vulnerability" | jq --argjson age "$age" --arg timestamp "$timestamp" '. + {age: $age, timestamp: $timestamp}')
              jq ". += [$updated_vulnerability]" "$temp_json" > temp.json.tmp && mv temp.json.tmp "$temp_json"
            done
          done

          # Move the temporary JSON to the output file in ../data
          mv "$temp_json" "../data/$output_json"

          # Create the summary report in text format
          high_count=$(jq '[.[] | select(.severity == "High")] | length' "../data/$output_json")
          medium_count=$(jq '[.[] | select(.severity == "Medium")] | length' "../data/$output_json")
          low_count=$(jq '[.[] | select(.severity == "Low")] | length' "../data/$output_json")

          summary_file="../data/vulnerability_summary_${timestamp}.txt"
          {
            echo "Total Vulnerabilities: $((high_count + medium_count + low_count))"
            echo "High: $high_count"
            jq -r '.[] | select(.severity == "High") | "\(.shortDescription), Path: \(.artifactLocationUri), Line: \(.startLine), Age: \(.age) days"' "../data/$output_json"
            echo "Medium: $medium_count"
            jq -r '.[] | select(.severity == "Medium") | "\(.shortDescription), Path: \(.artifactLocationUri), Line: \(.startLine), Age: \(.age) days"' "../data/$output_json"
            echo "Low: $low_count"
            jq -r '.[] | select(.severity == "Low") | "\(.shortDescription), Path: \(.artifactLocationUri), Line: \(.startLine), Age: \(.age) days"' "../data/$output_json"
          } > "$summary_file"

          # Print the file location and names
          echo "../data/"
          echo "$output_json"
          echo "$summary_file"

          # Print the name of the latest file checked
          echo "Latest file checked for age calculation: $latest_file"
        
        shell: bash

      - name: Upload SARIF file
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: snyk.sarif
